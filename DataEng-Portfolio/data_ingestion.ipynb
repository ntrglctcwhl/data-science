{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7837e35b",
   "metadata": {},
   "source": [
    "# Data Ingestion Notebook\n",
    "\n",
    "Source\n",
    "* https://trade.cites.org/\n",
    "* Download full database by clicking on button in orange banner at the top of the page\n",
    "\n",
    "CITES Trade Database User Guide\n",
    "* https://trade.cites.org/cites_trade_guidelines/en-CITES_Trade_Database_Guide.pdf\n",
    "\n",
    "Guidance for how to filter to elephants\n",
    "* https://cites.org/eng/prog/terrestrial_fauna/elephants#:~:text=African%20elephant%20(Loxodonta%20africana),Washington%20(Smithsonian%20Institution%20Press)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770f5747",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e35e73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2ff56a",
   "metadata": {},
   "source": [
    "## Set directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3a33f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_code = os.getcwd()\n",
    "dir_data = os.path.join(os.path.dirname(dir_code), \"data\")\n",
    "\n",
    "raw_zip_filename = \"Trade_database_download_v2025.1\"\n",
    "raw_zip_filepath = os.path.join(dir_data, f\"{raw_zip_filename}.zip\")\n",
    "\n",
    "dir_data_raw = os.path.join(dir_data, raw_zip_filename)\n",
    "\n",
    "raw_stacked_filename = \"cites_epehant_ivory_trades_raw_stacked.csv\"\n",
    "raw_stacked_filepath = os.path.join(dir_data, raw_stacked_filename)\n",
    "raw_stacked_exists = os.path.exists(raw_stacked_filepath)\n",
    "\n",
    "processed_filename = \"cites_elephant_ivory_trades_clean.csv\"\n",
    "processed_filepath = os.path.join(dir_data, processed_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582c3a83",
   "metadata": {},
   "source": [
    "## Read in raw elephant trade data\n",
    "\n",
    "This looks for a stacked CSV that only contains elephant-related trade data from the CITES Trade Database. If this stacked file does not exist, nothing will happen in this step and the code will proceed to run in the partitioned raw datasets. \n",
    "\n",
    "Adding this logic so we don't have to read in the partitioned raw data every single time -- it takes more time and creates a lot of output in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc55c717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 376965 entries, 0 to 376964\n",
      "Data columns (total 20 columns):\n",
      " #   Column                  Non-Null Count   Dtype \n",
      "---  ------                  --------------   ----- \n",
      " 0   Id                      376965 non-null  object\n",
      " 1   Year                    376965 non-null  object\n",
      " 2   Appendix                376965 non-null  object\n",
      " 3   Taxon                   376965 non-null  object\n",
      " 4   Class                   376965 non-null  object\n",
      " 5   Order                   376965 non-null  object\n",
      " 6   Family                  376965 non-null  object\n",
      " 7   Genus                   345608 non-null  object\n",
      " 8   Term                    376965 non-null  object\n",
      " 9   Quantity                376965 non-null  object\n",
      " 10  Unit                    74391 non-null   object\n",
      " 11  Importer                376410 non-null  object\n",
      " 12  Exporter                372347 non-null  object\n",
      " 13  Origin                  211240 non-null  object\n",
      " 14  Purpose                 314074 non-null  object\n",
      " 15  Source                  222506 non-null  object\n",
      " 16  Reporter.type           376965 non-null  object\n",
      " 17  Import.permit.RandomID  33216 non-null   object\n",
      " 18  Export.permit.RandomID  305248 non-null  object\n",
      " 19  Origin.permit.RandomID  8970 non-null    object\n",
      "dtypes: object(20)\n",
      "memory usage: 57.5+ MB\n"
     ]
    }
   ],
   "source": [
    "if raw_stacked_exists:\n",
    "    df_elephant_raw = pd.read_csv(raw_stacked_filepath, dtype=str)\n",
    "    df_elephant_raw.info()\n",
    "else:\n",
    "    print(\"Raw, stacked data with only elephant trades does not exist yet -- proceeding to run full ingestion proccess on the partitioned files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17395969",
   "metadata": {},
   "source": [
    "## Read in raw partitioned data (if ingestion process is being run for the first time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65f46b1",
   "metadata": {},
   "source": [
    "### a. Unzip folder containing the CITES Trade Database\n",
    "\n",
    "This assumes that if a separate folder exists with the same name as the zip folder, that you've already unzipped the data and all of the unzipped CSV files are in that folder. This can't tell if the zip was unsuccessful or only part of the files are in the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a75494d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingestion on the partitioned data has already been run -- skipping this step and reading from cites_epehant_ivory_trades_raw_stacked.csv\n"
     ]
    }
   ],
   "source": [
    "if not raw_stacked_exists:\n",
    "    if not os.path.exists(dir_data_raw):\n",
    "        os.makedirs(dir_data_raw)\n",
    "        with ZipFile(raw_zip_filepath, 'r') as raw_zip:\n",
    "            raw_zip.extractall(path = dir_data_raw)\n",
    "        print(f\"Data unzipped in {dir_data_raw}\")\n",
    "    else:\n",
    "        print(\"Data is already unzipped!\")\n",
    "else:\n",
    "    print(f\"Ingestion on the partitioned data has already been run -- skipping this step and reading from {raw_stacked_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008fee4c",
   "metadata": {},
   "source": [
    "### b. Identify CVS files that need to be read in\n",
    "\n",
    "These follow the pattern \"trade_db_[#].csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d1c9ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingestion on the partitioned data has already been run -- skipping this step and reading from cites_epehant_ivory_trades_raw_stacked.csv\n"
     ]
    }
   ],
   "source": [
    "if not raw_stacked_exists:\n",
    "    csv_files = glob.glob(os.path.join(dir_data_raw, \"trade_db_*.csv\"))\n",
    "    print(f\"There are {len(csv_files)} CSV files to read in\")\n",
    "else:\n",
    "    print(f\"Ingestion on the partitioned data has already been run -- skipping this step and reading from {raw_stacked_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef79a82f",
   "metadata": {},
   "source": [
    "### c. Read in and store only elephant-related trade records from each csv\n",
    "\n",
    "This process loops through each of the CSV and does the following:\n",
    "\n",
    "* Read in CSV\n",
    "* Filter only to elephant-related trade records\n",
    "    * Family = \"Elephantidae\"\n",
    "* Store filtered data partition in a list (this list will be concatentated into one master dataset after all files are read in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c06f0a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingestion on the partitioned data has already been run -- skipping this step and reading from cites_epehant_ivory_trades_raw_stacked.csv\n"
     ]
    }
   ],
   "source": [
    "if not raw_stacked_exists:\n",
    "    # Initialize empty list -- this is what we'll store the elephant-related trade records in from each csv\n",
    "    # -- Each element in this list is a dataframe corresponding to one of the CSVs in the zipped folder\n",
    "    elephant_partitions = []\n",
    "\n",
    "    # Loop through each CSV\n",
    "    for file in csv_files:\n",
    "        # Read in CSV file\n",
    "        print(f\"Reading in {file}...\")\n",
    "        df = pd.read_csv(file, dtype=str)\n",
    "\n",
    "        # Filter to elephant-related trade records\n",
    "        print(f\"-- Filtering to only trades involving elephants\")\n",
    "        df_elephants = df[df[\"Family\"] == \"Elephantidae\"]\n",
    "\n",
    "        # Add filtered df to elephant_partitions\n",
    "        elephant_partitions.append(df_elephants)\n",
    "        print(f\"-- Done with this file!\\n\")\n",
    "\n",
    "        # Delete stored partition dfs to clear memory\n",
    "        del df, df_elephants\n",
    "else:\n",
    "    print(f\"Ingestion on the partitioned data has already been run -- skipping this step and reading from {raw_stacked_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45092126",
   "metadata": {},
   "source": [
    "### d. Stack all partitions into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6ff1d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingestion on the partitioned data has already been run -- skipping this step and reading from cites_epehant_ivory_trades_raw_stacked.csv\n"
     ]
    }
   ],
   "source": [
    "if not raw_stacked_exists:\n",
    "    df_elephant_raw = pd.concat(elephant_partitions, ignore_index=True)\n",
    "    df_elephant_raw.info()\n",
    "else:\n",
    "    print(f\"Ingestion on the partitioned data has already been run -- skipping this step and reading from {raw_stacked_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894955f9",
   "metadata": {},
   "source": [
    "### e. Export this file so we don't have to rerun the part with CSV partitions every single team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a34de3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingestion on the partitioned data has already been run -- skipping this step and reading from cites_epehant_ivory_trades_raw_stacked.csv\n"
     ]
    }
   ],
   "source": [
    "if not raw_stacked_exists:\n",
    "    df_elephant_raw.to_csv(raw_stacked_filepath, index=False)\n",
    "else:\n",
    "    print(f\"Ingestion on the partitioned data has already been run -- skipping this step and reading from {raw_stacked_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393a33c1",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f1f0b3",
   "metadata": {},
   "source": [
    "### a. Explore trade terms (which ones relate to ivory?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3b5be29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['live', 'ivory carvings', 'tusks', 'ivory pieces', 'unspecified',\n",
       "       'leather products (small)', 'bodies', 'carvings', 'skin pieces',\n",
       "       'specimens', 'derivatives', 'bone products', 'trophies',\n",
       "       'leather items', 'feet', 'skulls', 'bone carvings', 'garments',\n",
       "       'teeth', 'shoes', 'bones', 'bone pieces', 'sets of piano keys',\n",
       "       'skeletons', 'leather products (large)', 'meat', 'skins', 'hair',\n",
       "       'hair products', 'tails', 'genitalia', 'ears', 'leather',\n",
       "       'skin scraps', 'ivory scraps', 'shells', 'furniture', 'roots',\n",
       "       'powder', 'sides', 'jewellery - ivory ', 'caviar', 'medicine',\n",
       "       'plates', 'piano keys', 'jewellery', 'trunk', 'extract',\n",
       "       'horn pieces', 'cloth', 'claws', 'fur products (large)',\n",
       "       'fur product (small)'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_elephant_raw[\"Term\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1fd281",
   "metadata": {},
   "source": [
    "### b. Flag trades containing ivory\n",
    "\n",
    "Any terms containing \"ivory\", \"tusk\", or \"piano\" will be treated as ivory trades. We cannot be certain about any of the other terms being ivory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10a6b83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ivory carvings', 'tusks', 'ivory pieces', 'sets of piano keys',\n",
       "       'ivory scraps', 'jewellery - ivory ', 'piano keys'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_elephant_raw.copy()\n",
    "\n",
    "# Flag ivory trades\n",
    "ivory_terms = [\"ivory\", \"tusk\", \"piano\"]\n",
    "df[\"ivory_trade\"] = df[\"Term\"].apply(lambda x: any(term in x.lower() for term in ivory_terms))\n",
    "\n",
    "# Confirm this worked\n",
    "df[df[\"ivory_trade\"] == True][\"Term\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65c2533",
   "metadata": {},
   "source": [
    "### c. Filter to ivory trades only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2be91e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 259902 trades that contain elephant ivory!\n"
     ]
    }
   ],
   "source": [
    "df = df[df[\"ivory_trade\"] == True]\n",
    "print(f\"We have {len(df)} trades that contain elephant ivory!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ff93e3",
   "metadata": {},
   "source": [
    "### d. Fill in blank \"Units\" values with \"Number of specimens\"\n",
    "\n",
    "Data usage guide explains that any trade records that do not have \"Units\" filled in means the units are \"Number of specimens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ca54e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'sets', 'kg', 'g', 'pairs', 'shipments', 'boxes', 'bags',\n",
       "       'cases', 'pieces', 'cartons', 'm', 'oz', 'cm', 'ml', 'm3',\n",
       "       'Number of specimens', 'cm3', 'm2'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore unique values to see exactly which one represents number of specimens\n",
    "# -- Copy/paste that value as what to fill blanks with\n",
    "df[\"Unit\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "078915bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Number of specimens    199561\n",
       "kg                      41257\n",
       "g                       12527\n",
       "sets                     4910\n",
       "pairs                    1214\n",
       "oz                        341\n",
       "shipments                  57\n",
       "boxes                      11\n",
       "cm                          5\n",
       "cases                       4\n",
       "m3                          3\n",
       "pieces                      3\n",
       "m                           3\n",
       "bags                        2\n",
       "cartons                     1\n",
       "ml                          1\n",
       "cm3                         1\n",
       "m2                          1\n",
       "Name: unit_clean, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"unit_clean\"] = df[\"Unit\"].fillna(\"Number of specimens\")\n",
    "df[\"unit_clean\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02eca248",
   "metadata": {},
   "source": [
    "### e. Filter to \"Number of specimens\" records only\n",
    "\n",
    "Trades where the unit is \"Number of specimens\" accounts for the vast majority of the data. There is no clear way to aggregate all of the units together in a way that preserves the true unit of the trade in a meaningful way (i.e. no clear conversion between \"kg\" or \"g\" and \"Number of specimens\"). Therefore we will drop anything that is not in a unit of \"Number of specimens\" to maintain reasonable data integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aec4f257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 199561 elephant ivory trades that are reported in units of 'Number of specimens'!\n"
     ]
    }
   ],
   "source": [
    "df = df[df[\"unit_clean\"] == \"Number of specimens\"]\n",
    "print(f\"We have {len(df)} elephant ivory trades that are reported in units of 'Number of specimens'!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d1c36e",
   "metadata": {},
   "source": [
    "### f. Replace unknown ISO country codes with NULL\n",
    "\n",
    "* According to data usage guide, country code \"XX\" represents an unknown ISO code. We should replace these with NULL so that this value does not get loaded as nodes, attributes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5280b69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List of columns that are populated with ISO codes\n",
    "cols_country_iso = [\"Importer\", \"Exporter\", \"Origin\"]\n",
    "\n",
    "# Replaec \"XX\" with NULL\n",
    "for col in cols_country_iso:\n",
    "    df[f\"{col.lower()}_clean\"] = df[col].replace(\"XX\", np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce70e8b9",
   "metadata": {},
   "source": [
    "### g. Drop trade records that have unknown or missing importing AND exporting countries\n",
    "\n",
    "We can only use records that have a known importer AND exporter in order to create graph relationships\n",
    "* We will drop a trade if we do not know the importing and exporting country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03f4e2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4969 records that have missing importer OR exporter information. Dropping these!\n",
      "We have 194592 elephant ivory trades with a known exporter -> importer path!\n"
     ]
    }
   ],
   "source": [
    "# Flag records where we do not know BOTH the importer and exporter\n",
    "df[\"bad_records_iso\"] = df[[\"importer_clean\", \"exporter_clean\"]].isnull().any(axis=1)\n",
    "print(f\"There are {df['bad_records_iso'].sum()} records that have missing importer OR exporter information. Dropping these!\")\n",
    "\n",
    "# Drop records with a full, known exporter -> importer path\n",
    "df = df[df[\"bad_records_iso\"] != 1]\n",
    "print(f\"We have {len(df)} elephant ivory trades with a known exporter -> importer path!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a2e08e",
   "metadata": {},
   "source": [
    "### h. Create numeric (integer) versions of \"Year\" and \"Quantity\" fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6aaee627",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"year_num\"] = pd.to_numeric(df[\"Year\"], errors=\"coerce\")\n",
    "df[\"quantity_num\"] = pd.to_numeric(df[\"Quantity\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230bf440",
   "metadata": {},
   "source": [
    "### i. Missing record check\n",
    "\n",
    "Make sure that all variables that must be populated for a given trade are populated.\n",
    "\n",
    "* ID\n",
    "* year_num\n",
    "* Taxon\n",
    "* Family\n",
    "* Term\n",
    "* quantity_num\n",
    "* unit_clean\n",
    "* importer_clean\n",
    "* exporter_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "408e45e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_mandatory = [\"Id\", \"year_num\", \"Taxon\", \"Family\", \"Term\", \"quantity_num\", \"unit_clean\", \"importer_clean\", \"exporter_clean\"]\n",
    "\n",
    "n_missing_mandatory = df[cols_mandatory].isnull().any(axis=1).sum()\n",
    "\n",
    "if n_missing_mandatory > 0:\n",
    "    raise ValueError(\"THERE ARE MISSING VALUES IN SOME MANDATORY COLUMNS REQUIRED FOR GRAPH CREATION. INVESTIGATE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3747d628",
   "metadata": {},
   "source": [
    "### j. Duplicate record checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55a2d9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Year</th>\n",
       "      <th>Appendix</th>\n",
       "      <th>Taxon</th>\n",
       "      <th>Class</th>\n",
       "      <th>Order</th>\n",
       "      <th>Family</th>\n",
       "      <th>Genus</th>\n",
       "      <th>Term</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>...</th>\n",
       "      <th>Export.permit.RandomID</th>\n",
       "      <th>Origin.permit.RandomID</th>\n",
       "      <th>ivory_trade</th>\n",
       "      <th>unit_clean</th>\n",
       "      <th>importer_clean</th>\n",
       "      <th>exporter_clean</th>\n",
       "      <th>origin_clean</th>\n",
       "      <th>bad_records_iso</th>\n",
       "      <th>year_num</th>\n",
       "      <th>quantity_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Id, Year, Appendix, Taxon, Class, Order, Family, Genus, Term, Quantity, Unit, Importer, Exporter, Origin, Purpose, Source, Reporter.type, Import.permit.RandomID, Export.permit.RandomID, Origin.permit.RandomID, ivory_trade, unit_clean, importer_clean, exporter_clean, origin_clean, bad_records_iso, year_num, quantity_num]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 28 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By all records\n",
    "df[df.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b18088b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Year</th>\n",
       "      <th>Appendix</th>\n",
       "      <th>Taxon</th>\n",
       "      <th>Class</th>\n",
       "      <th>Order</th>\n",
       "      <th>Family</th>\n",
       "      <th>Genus</th>\n",
       "      <th>Term</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>...</th>\n",
       "      <th>Export.permit.RandomID</th>\n",
       "      <th>Origin.permit.RandomID</th>\n",
       "      <th>ivory_trade</th>\n",
       "      <th>unit_clean</th>\n",
       "      <th>importer_clean</th>\n",
       "      <th>exporter_clean</th>\n",
       "      <th>origin_clean</th>\n",
       "      <th>bad_records_iso</th>\n",
       "      <th>year_num</th>\n",
       "      <th>quantity_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Id, Year, Appendix, Taxon, Class, Order, Family, Genus, Term, Quantity, Unit, Importer, Exporter, Origin, Purpose, Source, Reporter.type, Import.permit.RandomID, Export.permit.RandomID, Origin.permit.RandomID, ivory_trade, unit_clean, importer_clean, exporter_clean, origin_clean, bad_records_iso, year_num, quantity_num]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 28 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By ID column\n",
    "df[df.duplicated(subset=[\"Id\"], keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073c1e3b",
   "metadata": {},
   "source": [
    "### k. Create final dataset to use for graph\n",
    "\n",
    "* Only keep relevant columns that will be used in graph database\n",
    "* Convert all columns to lowercase\n",
    "* Rename columns if necessary\n",
    "* Sort data by year and taxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eccf0281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep relevant columns\n",
    "cols_keep = [\"Id\", \"year_num\", \"Taxon\", \"Family\", \"Term\", \"quantity_num\", \"unit_clean\", \"importer_clean\", \"exporter_clean\", \"origin_clean\"]\n",
    "df_final = df[cols_keep]\n",
    "\n",
    "# Convert all column names to lowercase\n",
    "df_final.columns = df_final.columns.str.lower()\n",
    "\n",
    "# Rename columns\n",
    "df_final = df_final.rename(columns = {\n",
    "    \"year_num\": \"year\",\n",
    "    \"quantity_num\": \"quantity\",\n",
    "    \"unit_clean\": \"unit\",\n",
    "    \"importer_clean\": \"importer\",\n",
    "    \"exporter_clean\": \"exporter\",\n",
    "    \"origin_clean\": \"origin\"\n",
    "})\n",
    "\n",
    "# Sort\n",
    "df_final = df_final.sort_values(by=[\"year\", \"taxon\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8375c5",
   "metadata": {},
   "source": [
    "## Preview and export cleaned dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2e12d3",
   "metadata": {},
   "source": [
    "### a. Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c336f9d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>taxon</th>\n",
       "      <th>family</th>\n",
       "      <th>term</th>\n",
       "      <th>quantity</th>\n",
       "      <th>unit</th>\n",
       "      <th>importer</th>\n",
       "      <th>exporter</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>761424121</td>\n",
       "      <td>1976</td>\n",
       "      <td>Elephas maximus</td>\n",
       "      <td>Elephantidae</td>\n",
       "      <td>ivory carvings</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Number of specimens</td>\n",
       "      <td>DE</td>\n",
       "      <td>IN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>301000281</td>\n",
       "      <td>1976</td>\n",
       "      <td>Elephas maximus</td>\n",
       "      <td>Elephantidae</td>\n",
       "      <td>ivory carvings</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Number of specimens</td>\n",
       "      <td>DE</td>\n",
       "      <td>IN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14893</th>\n",
       "      <td>2437221511</td>\n",
       "      <td>1977</td>\n",
       "      <td>Elephantidae spp.</td>\n",
       "      <td>Elephantidae</td>\n",
       "      <td>tusks</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Number of specimens</td>\n",
       "      <td>DK</td>\n",
       "      <td>NG</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>103564221</td>\n",
       "      <td>1977</td>\n",
       "      <td>Elephas maximus</td>\n",
       "      <td>Elephantidae</td>\n",
       "      <td>ivory carvings</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Number of specimens</td>\n",
       "      <td>CA</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21376</th>\n",
       "      <td>5571162511</td>\n",
       "      <td>1977</td>\n",
       "      <td>Loxodonta africana</td>\n",
       "      <td>Elephantidae</td>\n",
       "      <td>ivory pieces</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Number of specimens</td>\n",
       "      <td>US</td>\n",
       "      <td>GB</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376960</th>\n",
       "      <td>6430275356</td>\n",
       "      <td>2023</td>\n",
       "      <td>Loxodonta africana</td>\n",
       "      <td>Elephantidae</td>\n",
       "      <td>ivory carvings</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Number of specimens</td>\n",
       "      <td>ZA</td>\n",
       "      <td>GB</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375578</th>\n",
       "      <td>5472110955</td>\n",
       "      <td>2024</td>\n",
       "      <td>Loxodonta africana</td>\n",
       "      <td>Elephantidae</td>\n",
       "      <td>ivory pieces</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Number of specimens</td>\n",
       "      <td>US</td>\n",
       "      <td>MZ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375720</th>\n",
       "      <td>2335572955</td>\n",
       "      <td>2024</td>\n",
       "      <td>Loxodonta africana</td>\n",
       "      <td>Elephantidae</td>\n",
       "      <td>tusks</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Number of specimens</td>\n",
       "      <td>PA</td>\n",
       "      <td>CM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376701</th>\n",
       "      <td>3767382656</td>\n",
       "      <td>2024</td>\n",
       "      <td>Loxodonta africana</td>\n",
       "      <td>Elephantidae</td>\n",
       "      <td>ivory carvings</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Number of specimens</td>\n",
       "      <td>MY</td>\n",
       "      <td>MW</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376704</th>\n",
       "      <td>1248475356</td>\n",
       "      <td>2024</td>\n",
       "      <td>Loxodonta africana</td>\n",
       "      <td>Elephantidae</td>\n",
       "      <td>ivory carvings</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Number of specimens</td>\n",
       "      <td>MW</td>\n",
       "      <td>MY</td>\n",
       "      <td>MW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194592 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  year               taxon        family            term  \\\n",
       "105      761424121  1976     Elephas maximus  Elephantidae  ivory carvings   \n",
       "106      301000281  1976     Elephas maximus  Elephantidae  ivory carvings   \n",
       "14893   2437221511  1977   Elephantidae spp.  Elephantidae           tusks   \n",
       "158      103564221  1977     Elephas maximus  Elephantidae  ivory carvings   \n",
       "21376   5571162511  1977  Loxodonta africana  Elephantidae    ivory pieces   \n",
       "...            ...   ...                 ...           ...             ...   \n",
       "376960  6430275356  2023  Loxodonta africana  Elephantidae  ivory carvings   \n",
       "375578  5472110955  2024  Loxodonta africana  Elephantidae    ivory pieces   \n",
       "375720  2335572955  2024  Loxodonta africana  Elephantidae           tusks   \n",
       "376701  3767382656  2024  Loxodonta africana  Elephantidae  ivory carvings   \n",
       "376704  1248475356  2024  Loxodonta africana  Elephantidae  ivory carvings   \n",
       "\n",
       "        quantity                 unit importer exporter origin  \n",
       "105        100.0  Number of specimens       DE       IN    NaN  \n",
       "106         42.0  Number of specimens       DE       IN    NaN  \n",
       "14893        2.0  Number of specimens       DK       NG    NaN  \n",
       "158          1.0  Number of specimens       CA       US    NaN  \n",
       "21376        1.0  Number of specimens       US       GB    NaN  \n",
       "...          ...                  ...      ...      ...    ...  \n",
       "376960       1.0  Number of specimens       ZA       GB    NaN  \n",
       "375578     200.0  Number of specimens       US       MZ    NaN  \n",
       "375720       2.0  Number of specimens       PA       CM    NaN  \n",
       "376701      30.0  Number of specimens       MY       MW    NaN  \n",
       "376704      30.0  Number of specimens       MW       MY     MW  \n",
       "\n",
       "[194592 rows x 10 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d907cbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 194592 entries, 105 to 376704\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   id        194592 non-null  object \n",
      " 1   year      194592 non-null  int64  \n",
      " 2   taxon     194592 non-null  object \n",
      " 3   family    194592 non-null  object \n",
      " 4   term      194592 non-null  object \n",
      " 5   quantity  194592 non-null  float64\n",
      " 6   unit      194592 non-null  object \n",
      " 7   importer  194592 non-null  object \n",
      " 8   exporter  194592 non-null  object \n",
      " 9   origin    36958 non-null   object \n",
      "dtypes: float64(1), int64(1), object(8)\n",
      "memory usage: 16.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a66c343",
   "metadata": {},
   "source": [
    "### b. Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68ac17e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(processed_filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43ab531",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
